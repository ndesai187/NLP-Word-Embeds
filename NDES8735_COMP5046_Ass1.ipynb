{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NDES8735_COMP5046_Ass1 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGHoy6KpQDfZ"
      },
      "source": [
        "# COMP5046 Assignment 1\n",
        "*Make sure you change the file name with your unikey.*\n",
        "\n",
        "NDES8735 - Nirav Desai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qTf21j_oQIiD"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the user, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iXbQohXLKSgO"
      },
      "source": [
        "***Visualising the comparison of different results is a good way to justify your decision.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "34DVNKgqQY21"
      },
      "source": [
        "# 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7cWUxAQrGlq6"
      },
      "source": [
        "## 1.1. Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7T4IPBavoQ0Y",
        "outputId": "50e7b9f8-93d1-438d-9fb7-8fe706e0d9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Go5Tm1RPjAli",
        "outputId": "c13ae499-fef7-476c-9eb7-836011d80421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords as sw\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "save_path = '/content/drive/My Drive/COMP5046/assign_1/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U7C4snIcNl22",
        "outputId": "e0ce9604-a474-4bf2-db0a-86fcfe55d744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1vF3FqgBC1Y-RPefeVmY8zetdZG1jmHzT'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_train.csv')\n",
        "\n",
        "id = '1XhaV8YMuQeSwozQww8PeyiWMJfia13G6'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_test.csv')\n",
        "\n",
        "df_train = pd.read_csv(\"imdb_train.csv\")\n",
        "df_test = pd.read_csv(\"imdb_test.csv\")\n",
        "\n",
        "reviews_train = df_train['review'].tolist()\n",
        "sentiments_train = df_train['sentiment'].tolist()\n",
        "reviews_test = df_test['review'].tolist()\n",
        "sentiments_test = df_test['sentiment'].tolist()\n",
        "\n",
        "print(\"Training set number:\",len(reviews_train))\n",
        "print(\"Testing set number:\",len(reviews_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set number: 25000\n",
            "Testing set number: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S8_Iz3iv7WjP",
        "colab": {}
      },
      "source": [
        "# enable GPU here (cuda); or just CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fQeuUxOokt9V"
      },
      "source": [
        "## 1.2. Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8RdKI8E2KRwe"
      },
      "source": [
        "Following techniques are used for Data Preprocessing:\n",
        "1. General cleaning ::\n",
        "*   Casefolding - data was converted to lower case to reduce the vocabulary size. Words like 'Hello' and 'hello' will be treated in similar fashion.\n",
        "*   Tags and URL removal - The data contained some html tags and urls. As such, they will not add any extra information to our sentiment analysis task and removed to reduce overall vocabulary size.\n",
        "*   Special Character removal - During character embedding, it was noticed that there were number of special/non-english characters in the dataset. Since, our libraries (nltk etc) are based on English languge only, it was decided to remove these characters. There is a chance of information loss (change in meaning/word) becasue of that.\n",
        "*   Expanda contractions - To make it easier for \"stopword\" removal step, all known cotractions (including **capitalised** ) were expanded. For example \"Haven't\" expanded to 'have not'.\n",
        "*   Remove numbers and punctuations - Removed numbers and other punctuations that add noise to the dataset.\n",
        "\n",
        "2. Tokenization :: chopping each review document into word sequence. Tokenization will further help in lemmatization, stopword removal to preprocess data.\n",
        "\n",
        "3. Lemmetization :: Decided to use Lemmetization instead of stemming. Stemming can at times change the meaning of the word. Because our modeling is basic (only 1 window size for context), we can't rely on 1-window sized context for meaningful processing. Hence, decided to use only lemmatization instead of stemming.\n",
        "\n",
        "4. Stopword removal :: Removed commonly occurring stopword using nltk library. stopwords are common repitive words that add extra noise to word processing. Perormed at the end to maximise commond word removal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l9gBSgBCQh24"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "emyl1lWxGr12",
        "outputId": "35386d86-7f2d-4b87-bdf0-c63f718a679f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Please comment your code\n",
        "plt.hist(df_train['sentiment'], color = 'blue', edgecolor = 'black')\n",
        "plt.title('Histogram of Sentiment Classes')\n",
        "plt.xlabel('Sentiment Type')\n",
        "plt.ylabel('Total Samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Total Samples')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D1q_uLJBmehD"
      },
      "source": [
        "Based on above diagram, we can notice that our prediction is balanced binary sentiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZYbnR7kH3b1w"
      },
      "source": [
        "### 1.2.1 General cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HAKjXWJVmZ0E",
        "colab": {}
      },
      "source": [
        "# Removing punctuation, expanding contractions and removing <br /> tags\n",
        "\n",
        "# Taken from Lab 5\n",
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
        "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
        "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
        "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n",
        "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
        "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
        "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
        "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
        "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
        "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
        "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
        "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
        "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
        "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
        "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
        "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
        "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
        "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
        "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "cap_contraction_dict = {}\n",
        "\n",
        "# Taken from Lab5\n",
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "\n",
        "# Creating contractions dictionary with capitalised key value pairs.\n",
        "# This will cater edge condition for some of the contractions like 'Haven't'\n",
        "for k,v in contraction_dict.items():\n",
        "  cap_contraction_dict[k.capitalize()] = v.capitalize()\n",
        "\n",
        "contractions_dict = dict(contraction_dict)\n",
        "contractions_dict.update(cap_contraction_dict)\n",
        "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "\n",
        "# Expand contractions\n",
        "def expand_contractions(s, contractions_dict=contractions_dict):\n",
        "  def replace(match):\n",
        "    return contractions_dict[match.group(0)]\n",
        "  return contractions_re.sub(replace, s)\n",
        "\n",
        "# Remove punctuations\n",
        "def remove_punctuation(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        if punct in x:\n",
        "            x = x.replace(punct, ' ')\n",
        "    return x\n",
        "\n",
        "def preprocess_data(x):\n",
        "\n",
        "    # Change to lower case\n",
        "    x = x.lower()\n",
        "\n",
        "    # Remove html tags such as <br />\n",
        "    x_tag = re.sub(r'<[^<]+?>',' ',x)\n",
        "\n",
        "    # Expand contractions\n",
        "    x_contractions = expand_contractions(x_tag)\n",
        "\n",
        "    # Remove site URLs\n",
        "    x_url = re.sub(r'http\\S+', ' ',x_contractions)\n",
        "\n",
        "    # Remove special characters\n",
        "    x_spl_chars = re.sub(r'[^A-Za-z0-9 ]+', ' ', x_url)\n",
        "\n",
        "    # Remove numbers\n",
        "    x_nums = re.sub(r'\\d',' ',x_spl_chars)\n",
        "    \n",
        "    # Remove punctuations\n",
        "    x_punctuate = remove_punctuation(x_nums)\n",
        "\n",
        "    # Remove underscores '_'\n",
        "    x_cleaned = re.sub(r'\\_',' ',x_punctuate)   \n",
        "\n",
        "    return x_cleaned\n",
        "\n",
        "reviews_train_re = [preprocess_data(s) for s in reviews_train]\n",
        "reviews_test_re = [preprocess_data(s) for s in reviews_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fFLxKJiW3TV6"
      },
      "source": [
        "### 1.2.2 Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_zwTl2Ck4vdh",
        "colab": {}
      },
      "source": [
        "# Tokenization\n",
        "tknzr = TweetTokenizer()\n",
        "\n",
        "reviews_train_tk = [tknzr.tokenize(s) for s in reviews_train_re] \n",
        "reviews_test_tk = [tknzr.tokenize(s) for s in reviews_test_re]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5NQwicw3kPT"
      },
      "source": [
        "### 1.2.3 Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ITaWt2egaCh0",
        "colab": {}
      },
      "source": [
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatizer_list(seq_list):\n",
        "  ls_lemmatized = []\n",
        "  for tokens in seq_list:\n",
        "    filtered_sentence = [lemmatizer.lemmatize(w) for w in tokens ]\n",
        "    ls_lemmatized.append(filtered_sentence)\n",
        "  return ls_lemmatized\n",
        "\n",
        "reviews_train_lm = lemmatizer_list(reviews_train_tk)\n",
        "reviews_test_lm = lemmatizer_list(reviews_test_tk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MmezjVotS2k4"
      },
      "source": [
        "### 1.2.4 Stopword removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aekgaHjwmZqe",
        "colab": {}
      },
      "source": [
        "#Stopword Removal\n",
        "stop_words = sw.words()\n",
        "\n",
        "def stopword_removal(seq_list):\n",
        "  ls_no_stopword = []\n",
        "  for tokens in seq_list:\n",
        "    filtered_sentence = [w for w in tokens if not w in stop_words]\n",
        "    ls_no_stopword.append(filtered_sentence)\n",
        "  return ls_no_stopword\n",
        "\n",
        "reviews_train_sw = stopword_removal(reviews_train_lm)\n",
        "reviews_test_sw = stopword_removal(reviews_test_lm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jqQ3i_r7S8u0"
      },
      "source": [
        "Save cleaned data for future use and saving reprocessing time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ONhiS1SmmZKF",
        "colab": {}
      },
      "source": [
        "# Save cleaned data\n",
        "zippedList =  list(zip(reviews_train_sw, reviews_test_sw))\n",
        "dfObj = pd.DataFrame(zippedList, columns = ['reviews_train_sw' , 'reviews_test_sw']) \n",
        "\n",
        "with open(save_path + 'cleaned_data.pkl', 'wb') as f:\n",
        "    pickle.dump(dfObj, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LIu_lkJwQ55g"
      },
      "source": [
        "# 2 - Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "daDvAftceIvr"
      },
      "source": [
        "## 2.1. Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lbzm-NWBTmM-"
      },
      "source": [
        "**Model Selection**\n",
        "\n",
        "*   Considering the size of the dataset, fasttext was ruled out. The n-grams used for fast text will need significantly higher resources that current colab environment.\n",
        "*   Using word2vec skipgram model - Between CBOW and skipgram, I decided to choose skipgram just for a trial.\n",
        "\n",
        "Each section will have explanation on approach taken. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GXgFpxIgl-_G"
      },
      "source": [
        "### 2.1.1. Data Preprocessing for Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qJrVHGYSmYMg"
      },
      "source": [
        "*   Merged train and test data to create master list of all available words.\n",
        "*   Padding - To make uniform input document length, we padded all documents based on maximum length of a document.\n",
        "*   Create Skipgrams - Based on unique word and index, skipgrams were created for numeric (index) representation of target and context word. Window size of **more than 1** always crashes colab notebook and hence I kept it to minimum window size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sndey6CxsvDZ",
        "outputId": "bc30f303-cbf5-4cd6-95d6-c9d8277d1a9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "with open(save_path + 'cleaned_data.pkl', 'rb') as f:\n",
        "    cleaned_df_obj = pickle.load(f)\n",
        "\n",
        "cleaned_df_obj.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews_train_sw</th>\n",
              "      <th>reviews_test_sw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[enjoyed, movie, seen, andy, griffith, age, fe...</td>\n",
              "      <td>[course, going, think, wa, great, movie, recog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[whole, doe, even, close, sum, part, problem, ...</td>\n",
              "      <td>[never, understood, type, spoof, movie, get, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[would, never, seen, independent, movie, wa, r...</td>\n",
              "      <td>[first, awful, rating, ever, imdb, could, thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[unpleasant, film, little, recommend, dolph, l...</td>\n",
              "      <td>[quite, bad, movie, oh, well, movie, least, la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[wa, meant, parody, lotr, trilogy, wa, awful, ...</td>\n",
              "      <td>[horrific, make, french, movie, vie, rose, sce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    reviews_train_sw                                    reviews_test_sw\n",
              "0  [enjoyed, movie, seen, andy, griffith, age, fe...  [course, going, think, wa, great, movie, recog...\n",
              "1  [whole, doe, even, close, sum, part, problem, ...  [never, understood, type, spoof, movie, get, s...\n",
              "2  [would, never, seen, independent, movie, wa, r...  [first, awful, rating, ever, imdb, could, thin...\n",
              "3  [unpleasant, film, little, recommend, dolph, l...  [quite, bad, movie, oh, well, movie, least, la...\n",
              "4  [wa, meant, parody, lotr, trilogy, wa, awful, ...  [horrific, make, french, movie, vie, rose, sce..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VyEXA76Rs8Ge",
        "colab": {}
      },
      "source": [
        "reviews_train_clean = cleaned_df_obj['reviews_train_sw'].tolist()\n",
        "reviews_test_clean = cleaned_df_obj['reviews_test_sw'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5vWoL1zx-Wsb",
        "outputId": "9a8bb529-7cf4-4fa0-9b45-5bcc255d557d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Merging training and test dataset for embedding training\n",
        "total_reviews = []\n",
        "\n",
        "[total_reviews.append(review) for review in reviews_train_clean]\n",
        "[total_reviews.append(review) for review in reviews_test_clean]\n",
        "print(\"Merged train and test reviews to process word embeddings\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Merged train and test reviews to process word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aRwknSJu8rw_",
        "outputId": "93644f7f-f061-468e-8f1d-62be5a24cf02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Padding reviews to make equal length - pick maximum review length for padding\n",
        "len_list = [len(s) for s in total_reviews]\n",
        "seq_length = max(len_list)\n",
        "print(\"Maximum length is : {}\".format(seq_length))\n",
        "\n",
        "def add_padding(corpus, seq_length):\n",
        "    output = []\n",
        "    for sentence in corpus:\n",
        "        if len(sentence)>seq_length:\n",
        "            output.append(sentence[:seq_length])\n",
        "        else:\n",
        "            for j in range(seq_length-len(sentence)):\n",
        "                sentence.append(\"<PAD>\")\n",
        "            output.append(sentence)\n",
        "    return output\n",
        "\n",
        "total_reviews = add_padding(total_reviews,seq_length )\n",
        "print(\"Each review is padded to length : {}\".format( set( [len(s) for s in total_reviews])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length is : 1385\n",
            "Each review is padded to length : {1385}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3LByzHLiNinu",
        "colab": {}
      },
      "source": [
        "# Coverting all words to unique word dictionary\n",
        "\n",
        "word_sequence = []\n",
        "for review in total_reviews:\n",
        "  for word in review:\n",
        "    word_sequence.append(word)\n",
        "\n",
        "word_list = list(set(word_sequence))\n",
        "word_list.sort()\n",
        "\n",
        "# make dictionary so that we can be reference each index of unique word\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "word_dict['<PAD>'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0TGjk6xMcP13",
        "outputId": "3b341242-3dfe-4066-c831-d3a9eac59cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "voc_size = len(word_list)\n",
        "print(\"Vocab size is : {}, and total words are : {}\".format(voc_size, len(word_sequence)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size is : 89043, and total words are : 69250000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BtS_uzecub__",
        "colab": {}
      },
      "source": [
        "# Making window size 1 skip-gram\n",
        "skip_grams = []\n",
        "skip_gram_window = 1\n",
        "\n",
        "for i in range(1, len(word_sequence) - 1):\n",
        "    # (context, target) : ([target index - skip_gram_window, target index + skip_gram_window], target)\n",
        "    target = word_dict[word_sequence[i]]\n",
        "    context = [word_dict[word_sequence[i - skip_gram_window]], word_dict[word_sequence[i + skip_gram_window]]]\n",
        "    # skipgrams - (target, context[0]), (target, context[1])..\n",
        "    for w in context:\n",
        "        skip_grams.append([target, w])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m9cnFO035Hwn",
        "outputId": "867bbf87-c175-4542-fba9-4a063b2a693e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(skip_grams)\n",
        "skip_grams[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[52188, 24940], [52188, 69462], [69462, 52188], [69462, 2720], [2720, 69462]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rd4oNRzOVAoQ",
        "colab": {}
      },
      "source": [
        "# dfObj = pd.DataFrame(skip_grams) \n",
        "\n",
        "# with open('/content/skip_grams.pkl', 'wb') as f:\n",
        "#     pickle.dump(dfObj, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FYG2Jepuuh2A",
        "colab": {}
      },
      "source": [
        "# prepare random batch from skip-gram - we have large number of skipgrams.\n",
        "# Since we can't train model for all skipgrams,  we randomly select data\n",
        "def prepare_batch(data, size):\n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(data)), size, replace=False)\n",
        "\n",
        "    for i in random_index:\n",
        "        input_temp = [0]*voc_size\n",
        "        input_temp[data[i][0]] = 1\n",
        "        random_inputs.append(input_temp)  # target\n",
        "        random_labels.append(data[i][1])  # context word\n",
        "\n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qhAgWf_AmbZ8"
      },
      "source": [
        "### 2.1.2. Build Word Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AJ8rU7JbiBVS"
      },
      "source": [
        "Used following combination of parameter:\n",
        "\n",
        "1.  Learning rate :: [0.1, 0.05] :: The loss was higher and unstable for learning rate of 0.1 and hence I lowered learning rate to 0.05.\n",
        "2.  Batch size :: [200, 250, 300] :: Anything greater than 200 crashes the colab runtime and hence I kept to maximum acceptable value i.e. 200.\n",
        "3.  Embedding size :: [50, 100] :: Between these  2 values, 100 gives a better results with reduced loss. However, there is performance impact. embedding size of 50 is much faster.\n",
        "4. epochs :: [30, 50, 100] :: The results improve with higher epochs value. However, 50 epochs still gave low loss values. I decided to choose 50 as a trade off for perfomance and runtime.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xwkOj6SxumdD",
        "colab": {}
      },
      "source": [
        "# hyperparameters\n",
        "learning_rate = 0.05\n",
        "batch_size = 200\n",
        "embedding_size = 100\n",
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TVPuwWgvNjOU",
        "colab": {}
      },
      "source": [
        "# Define model\n",
        "class SkipGram(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.linear1 = nn.Linear(voc_size, embedding_size, bias=False)\n",
        "        self.linear2 = nn.Linear(embedding_size, voc_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.linear1(x)\n",
        "        out = self.linear2(hidden)\n",
        "        return out\n",
        "\n",
        "skip_gram_model = SkipGram()\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimiser = optim.Adam(skip_gram_model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LNys5HOdISK-"
      },
      "source": [
        "### 2.1.3. Train Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ae8i7Z2kIef-",
        "outputId": "d0ec8cc3-4d22-42db-fec5-e859ba07ec86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    inputs,labels = prepare_batch(skip_grams, batch_size)\n",
        "    inputs_torch = torch.from_numpy(inputs).float()\n",
        "    labels_torch = torch.from_numpy(labels)\n",
        "\n",
        "    skip_gram_model.train()\n",
        "\n",
        "    # 1. zero grad\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    # 2. forword propagation\n",
        "    # 3. calculate loss\n",
        "    # 4. back propagation\n",
        "    outputs = skip_gram_model(inputs_torch)\n",
        "    loss = criterion(outputs, labels_torch)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    if epoch % 5 == 4: \n",
        "        print('Epoch: %d, loss: %.4f' %(epoch + 1, loss))\n",
        "\n",
        "weight1 = skip_gram_model.linear1.weight \n",
        "trained_embeddings = weight1.detach().T.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5, loss: 7.2385\n",
            "Epoch: 10, loss: 0.6258\n",
            "Epoch: 15, loss: 0.7407\n",
            "Epoch: 20, loss: 1.0992\n",
            "Epoch: 25, loss: 0.8545\n",
            "Epoch: 30, loss: 1.0687\n",
            "Epoch: 35, loss: 0.9708\n",
            "Epoch: 40, loss: 1.0944\n",
            "Epoch: 45, loss: 1.3200\n",
            "Epoch: 50, loss: 0.6171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uMCv3YI1IfUo"
      },
      "source": [
        "### 2.1.4. Save Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3OwicNPkIqd1",
        "outputId": "437cc350-4ba8-44a3-c84d-14dde1e982e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "torch.save(skip_gram_model, save_path + 'ndes8735_word.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SkipGram. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yn16xrDrIs8B"
      },
      "source": [
        "### 2.1.5. Load Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-IebpYFsIvgh",
        "outputId": "69b2f418-de60-4f29-fe3f-9fd84997ab00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "skip_gram_word2Vec_model = torch.load(save_path + 'ndes8735_word.pt')\n",
        "skip_gram_word2Vec_model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SkipGram(\n",
              "  (linear1): Linear(in_features=89043, out_features=100, bias=False)\n",
              "  (linear2): Linear(in_features=100, out_features=89043, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T0ap96aeGlIk"
      },
      "source": [
        "## 2.2. Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d16v3oKaGlI0"
      },
      "source": [
        "### 2.2.1. Data Preprocessing for Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AKbLnN-3GlI1"
      },
      "source": [
        "Used similar techniques as in Word Embedding preprocessing, but applied on character level. such as ::\n",
        "\n",
        "*   Padding - To make uniform input word length, we padded all words based on maximum length of a word i.e. 72.\n",
        "*   Based on unique characters and index, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2CUCL1cGlI2",
        "colab": {}
      },
      "source": [
        "# Coverting all words to unique character dictionary\n",
        "\n",
        "char_sequence = [list(w) for w in word_list]\n",
        "\n",
        "# Adding character set for PAD place holder\n",
        "[char_sequence.append(list(w)) for w in '<PAD>']\n",
        "\n",
        "all_chars = []\n",
        "for item in char_sequence:\n",
        "  for char in item:\n",
        "    all_chars.append(char)\n",
        "\n",
        "char_list = list(set(all_chars))\n",
        "char_list.sort()\n",
        "\n",
        "# make dictionary so that we can be reference each index of unique word\n",
        "char_dict = {w: i+1 for i, w in enumerate(char_list)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GaZErYBxntTK",
        "outputId": "36be33af-8a9a-4c3f-c26f-3cc107b81cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "max_char_len = max([len(word) for word in word_list])\n",
        "print(\"Maximum word length to be used for padding : {}\".format(max_char_len))\n",
        "print(\"\\nWords greater than length of 50...\")\n",
        "print([word for word in word_list if len(word) > 50])\n",
        "print(\"\\nCharacter dictionary\")\n",
        "print(char_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum word length to be used for padding : 72\n",
            "\n",
            "Words greater than length of 50...\n",
            "['blahblahblahblahblahblahblahblahblahblahblahblahblahblahblahblahblahblah', 'caaaaaaaaaaaaaaaaaaaaaaligulaaaaaaaaaaaaaaaaaaaaaaa', 'isaboutaguylookingforthewomanwhosavedhisgrandpafromthenazis']\n",
            "\n",
            "Character dictionary\n",
            "{'<': 1, '>': 2, 'A': 3, 'B': 4, 'D': 5, 'P': 6, 'a': 7, 'b': 8, 'c': 9, 'd': 10, 'e': 11, 'f': 12, 'g': 13, 'h': 14, 'i': 15, 'j': 16, 'k': 17, 'l': 18, 'm': 19, 'n': 20, 'o': 21, 'p': 22, 'q': 23, 'r': 24, 's': 25, 't': 26, 'u': 27, 'v': 28, 'w': 29, 'x': 30, 'y': 31, 'z': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-cxI5FYtPtZ",
        "outputId": "51d4837f-9245-48c5-fbc7-9acbf62e3388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "len_list = [len(s) for s in char_sequence]\n",
        "seq_length = max(len_list)\n",
        "print(\"Maximum word length is : {}\".format(seq_length))\n",
        "\n",
        "def add_padding_char(corpus, seq_length):\n",
        "    output = []\n",
        "    for sentence in corpus:\n",
        "        if len(sentence)>seq_length:\n",
        "            output.append(sentence[:seq_length])\n",
        "        else:\n",
        "            for j in range(seq_length-len(sentence)):\n",
        "                sentence.append(\"$\")\n",
        "            output.append(sentence)\n",
        "    return output\n",
        "\n",
        "char_sequence_padded = add_padding_char(char_sequence,seq_length )\n",
        "char_dict['$'] = 0\n",
        "print(\"Each word is padded to length : {}\".format( set( [len(s) for s in char_sequence_padded])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum word length is : 72\n",
            "Each word is padded to length : {72}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5FzGkkPlEv2g",
        "colab": {}
      },
      "source": [
        "# Prepare indexed character input\n",
        "char_input_seq = []\n",
        "\n",
        "for item in char_sequence_padded:\n",
        "  char_input_seq.append([char_dict[c] for c in item])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qOqZh2kFdlJ",
        "outputId": "b6e02a5a-4a62-44e7-b735-c0de665bb96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"A sample encoded word...\")\n",
        "print(char_input_seq[5678])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A sample encoded word...\n",
            "[8, 7, 18, 19, 11, 10, 10, 15, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgiOPcsTGlI6"
      },
      "source": [
        "### 2.2.2. Build Character Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4NtqFFcjGlI7"
      },
      "source": [
        "Used following combination of parameter:\n",
        "\n",
        "1.  Learning rate :: 0.05\n",
        "2.  Batch size :: [1024, 2048] :: Batch size of 2048 has significantly high processing time. Hence, I decided to keep 1024.\n",
        "3. epochs :: [20,30,50] :: The processing time for each epoch is significantly high due to higher batch size. Between reducing batch size and epoch, I decided to keep minimum epochs of 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jj3YZ3PWGlI8",
        "colab": {}
      },
      "source": [
        "### Setting hyperparameters\n",
        "\n",
        "learning_rate = 0.05\n",
        "n_hidden = 50\n",
        "total_epoch = 20\n",
        "\n",
        "# Number of sequences for RNN = max word length\n",
        "n_step = seq_length\n",
        "\n",
        "# number of inputs\n",
        "n_input = len(char_dict)\n",
        "# number of classes\n",
        "n_class = len(word_dict)\n",
        "batch_size = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ts8-vrh39Bip",
        "colab": {}
      },
      "source": [
        "# Define batching \n",
        "def make_batch(seq_data, word_embeddings):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    \n",
        "    for i in range(word_embeddings.shape[0]):       \n",
        "        # convert input to one-hot encoding.\n",
        "        # if input is [3, 4, 4]:\n",
        "        # [[ 0,  0,  0,  1,  0,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]]\n",
        "        input_batch.append(np.eye(n_input)[seq_data[i]])  \n",
        "        target_batch.append(word_embeddings[i])\n",
        "\n",
        "    return input_batch, target_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DWoFQsxQA82E",
        "colab": {}
      },
      "source": [
        "# Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden, batch_first =True,bidirectional=True, dropout=0.3)\n",
        "        self.linear = nn.Linear(n_hidden*2,n_class)\n",
        "        self.linear_char = nn.Linear(n_class,n_hidden*2)\n",
        "\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        #h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        lstm_out, (h_n,c_n) = self.lstm(sentence)\n",
        "        #concat the last hidden state from two direction\n",
        "        hidden_out =torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        z_char = self.linear_char(z)\n",
        "        return z_char,hidden_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46W0zFfWGlI_"
      },
      "source": [
        "### 2.1.4. Train Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rlSwzouQUeVd",
        "outputId": "333edfb6-3c51-41e2-c970-1d0bb29999a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load word embedding for training character model \n",
        "skip_gram_word2Vec_model = torch.load(save_path + 'ndes8735_word.pt')\n",
        "trained_word_embeddings_torch = skip_gram_word2Vec_model.linear1.weight.data\n",
        "trained_word_embeddings = trained_word_embeddings_torch.detach().T.numpy()\n",
        "\n",
        "print(\"Shape of word embedding model : \")\n",
        "print(trained_word_embeddings.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of word embedding model : \n",
            "(89043, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UWQn-VyNGlJA",
        "outputId": "c8df908a-abc5-4e2e-8456-c3b761917ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Move the model to GPU\n",
        "net = Net()\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "\n",
        "    for i in range(0, trained_word_embeddings.shape[0], batch_size): \n",
        "        # Preparing input\n",
        "        input_batch, target_batch = make_batch(char_input_seq[i: i+batch_size], trained_word_embeddings[i: i+batch_size])\n",
        "        # Convert input into tensors and move them to GPU by uting tensor.to(device)\n",
        "        input_batch_torch = torch.from_numpy(np.array(input_batch)).float()\n",
        "        target_batch_torch = torch.from_numpy(np.array(target_batch))\n",
        "\n",
        "        # Set the flag to training\n",
        "        net.train()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs,_ = net(input_batch_torch) \n",
        "        loss = criterion(outputs, target_batch_torch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # Set the flag to evaluation, which will 'turn off' the dropout\n",
        "    net.eval()\n",
        "    outputs,_ = net(input_batch_torch) \n",
        "    \n",
        "    # Evaluation loss\n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    if epoch % 5 == 4: \n",
        "      print('Epoch: %d, loss: %.5f' %(epoch + 1, loss.item()))\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5, loss: 10.51139\n",
            "Epoch: 10, loss: 1.71536\n",
            "Epoch: 15, loss: 5.85946\n",
            "Epoch: 20, loss: 2.76535\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5Bym9bBGlJE"
      },
      "source": [
        "### 2.1.5. Save Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggTsYIm7GlJF",
        "outputId": "aac56c0a-2509-4d8a-e6cb-89885f140cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "torch.save(net, save_path + 'ndes8735_character.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JwOI-wIKGlJI"
      },
      "source": [
        "### 2.1.6. Load Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4-jyj-lOHWWj",
        "outputId": "e2886162-cba3-4a50-8b57-ca268409cf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "char_embed_model = torch.load(save_path + 'ndes8735_character.pt')\n",
        "char_embed_model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (lstm): LSTM(33, 50, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (linear): Linear(in_features=100, out_features=89043, bias=True)\n",
              "  (linear_char): Linear(in_features=89043, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tlCeWT8eeLnd"
      },
      "source": [
        "## 2.3. Sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fwA-NN3EJ4Ig"
      },
      "source": [
        "### 2.3.1. Apply/Import Word Embedding and Character Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UAMJrxx-iOVn"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rh0uNbXPP1R4",
        "outputId": "71a48c61-e616-411a-865b-f4c7e5f30d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Load word2vec embeddings\n",
        "skip_gram_word2Vec_model = torch.load(save_path + 'ndes8735_word.pt')\n",
        "skip_gram_word2Vec_model.eval()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SkipGram(\n",
              "  (linear1): Linear(in_features=89043, out_features=100, bias=False)\n",
              "  (linear2): Linear(in_features=100, out_features=89043, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lxxo68ngP1FW",
        "outputId": "f318afe3-2e9c-4f0b-fb83-a6f63741ba2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Load char embeddings\n",
        "char_embed_model = torch.load(save_path + 'ndes8735_character.pt')\n",
        "char_embed_model.eval()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (lstm): LSTM(33, 50, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (linear): Linear(in_features=100, out_features=89043, bias=True)\n",
              "  (linear_char): Linear(in_features=89043, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g7PKX1gIePA2",
        "colab": {}
      },
      "source": [
        "# Fetch trained embeddings from weights\n",
        "\n",
        "trained_word_embeddings = skip_gram_word2Vec_model.linear1.weight.data.T\n",
        "trained_char_embeddings = char_embed_model.linear_char.weight.data.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cNFVPcXLPO8m",
        "outputId": "3bbed1f3-9ca7-4611-9182-cae5613093dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Merge embeddings\n",
        "\n",
        "merged_embeddings_torch = torch.cat((trained_word_embeddings, trained_char_embeddings), 1)\n",
        "print(merged_embeddings_torch.shape)\n",
        "\n",
        "merged_embeddings = merged_embeddings_torch.detach().numpy().tolist()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([89043, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fsmsFOPXQ4Rg",
        "outputId": "31b1110b-3e81-4457-df13-8e0713c76318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Prepare training and test data\n",
        "with open(save_path + 'cleaned_data.pkl', 'rb') as f:\n",
        "    cleaned_df_obj = pickle.load(f)\n",
        "\n",
        "cleaned_df_obj.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews_train_sw</th>\n",
              "      <th>reviews_test_sw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[enjoyed, movie, seen, andy, griffith, age, fe...</td>\n",
              "      <td>[course, going, think, wa, great, movie, recog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[whole, doe, even, close, sum, part, problem, ...</td>\n",
              "      <td>[never, understood, type, spoof, movie, get, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[would, never, seen, independent, movie, wa, r...</td>\n",
              "      <td>[first, awful, rating, ever, imdb, could, thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[unpleasant, film, little, recommend, dolph, l...</td>\n",
              "      <td>[quite, bad, movie, oh, well, movie, least, la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[wa, meant, parody, lotr, trilogy, wa, awful, ...</td>\n",
              "      <td>[horrific, make, french, movie, vie, rose, sce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    reviews_train_sw                                    reviews_test_sw\n",
              "0  [enjoyed, movie, seen, andy, griffith, age, fe...  [course, going, think, wa, great, movie, recog...\n",
              "1  [whole, doe, even, close, sum, part, problem, ...  [never, understood, type, spoof, movie, get, s...\n",
              "2  [would, never, seen, independent, movie, wa, r...  [first, awful, rating, ever, imdb, could, thin...\n",
              "3  [unpleasant, film, little, recommend, dolph, l...  [quite, bad, movie, oh, well, movie, least, la...\n",
              "4  [wa, meant, parody, lotr, trilogy, wa, awful, ...  [horrific, make, french, movie, vie, rose, sce..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bv8CiQyRQ3qx",
        "outputId": "3858372c-e8e2-4ce2-da87-91507c115d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Prepare inputs\n",
        "reviews_train_clean = cleaned_df_obj['reviews_train_sw'].tolist()\n",
        "reviews_test_clean = cleaned_df_obj['reviews_test_sw'].tolist()\n",
        "sentiments_train = df_train['sentiment'].tolist()\n",
        "sentiments_test = df_test['sentiment'].tolist()\n",
        "\n",
        "print(\"Training data size : data = {}, lables = {}\".format(len(reviews_train_clean), len(sentiments_train)))\n",
        "print('Word Embedding Shape : {}'.format(trained_word_embeddings.shape))\n",
        "print('Character Embedding Shape : {}'.format(trained_char_embeddings.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size : data = 25000, lables = 25000\n",
            "Word Embedding Shape : torch.Size([89043, 100])\n",
            "Character Embedding Shape : torch.Size([89043, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TomdShl7R0HK",
        "outputId": "ca44ce28-0b5a-4e76-c8bb-496c35c5022c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# encode output labels to class 0 and 1\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labels = np.unique(sentiments_train)\n",
        "\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(labels)\n",
        "label_train_n = lEnc.transform(sentiments_train)\n",
        "label_test_n = lEnc.transform(sentiments_test)\n",
        "numClass = len(labels)\n",
        "\n",
        "print(labels)\n",
        "print(lEnc.transform(labels))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neg' 'pos']\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ywv0NcxadGF",
        "outputId": "e1f34f0d-58b1-4c0a-e8ea-6e8ca63ff3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Pad the data same as word2vec model\n",
        "len_list = [len(s) for s in total_reviews]\n",
        "seq_length = max(len_list)\n",
        "#print(seq_length)\n",
        "\n",
        "data_train = add_padding(reviews_train_clean,seq_length )\n",
        "data_test = add_padding(reviews_test_clean,seq_length )\n",
        "\n",
        "print(\"Maximum review length after cleaning and preprocessing ...\")\n",
        "print(set( [len(s) for s in data_train]))\n",
        "print(set( [len(s) for s in data_test]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length after cleaning and preprocessing ...\n",
            "{1385}\n",
            "{1385}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DpYCL17JKZxl"
      },
      "source": [
        "### 2.3.2. Build Sequence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R204UIyDKhZ4"
      },
      "source": [
        "Epochs - Tried with 100 and 150. There is no significant improvement after 100 epochs and hence I decided to keep it to minimum value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "13eCtR_SLUG6",
        "colab": {}
      },
      "source": [
        "# Hyper params\n",
        "n_input = merged_embeddings_torch.shape[1]\n",
        "n_hidden = 50\n",
        "n_class = len(labels)\n",
        "batch_size = 200\n",
        "epochs = 100\n",
        "learning_rate = 0.05\n",
        "\n",
        "# Perfomance arrays\n",
        "f1_score_list = []\n",
        "accuracy_score_list = []\n",
        "epoch_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SRrh8AMMebgw",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "class Sentiment_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Sentiment_Model, self).__init__()\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden, batch_first =True,bidirectional=True, dropout=0.3)\n",
        "        self.linear = nn.Linear(n_hidden*2,n_class)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        \n",
        "        #h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        lstm_out, (h_n,c_n) = self.lstm(sentence)\n",
        "        #concat the last hidden state from two direction\n",
        "        hidden_out =torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        log_output = F.log_softmax(z, dim=1)\n",
        "        return log_output,hidden_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kCMQrDqeg_Q9",
        "colab": {}
      },
      "source": [
        "# prepare random batch for sequence model\n",
        "def prepare_batch_final(data, labels, size):\n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(data)), size, replace=True)\n",
        "\n",
        "    for i in random_index:\n",
        "        random_inputs.append(data[i])  # review\n",
        "        random_labels.append(labels[i])  # sentiment\n",
        "\n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6BaOiaGRLW7R"
      },
      "source": [
        "### 2.3.3. Train Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o3biFVPgnxos",
        "colab": {}
      },
      "source": [
        "# Get embeddings for each review and word\n",
        "def get_merged_embeddings(reviews):\n",
        "    m_embed_list = []\n",
        "    for review in reviews:\n",
        "        tmp = []\n",
        "        for w in review:\n",
        "            idx = word_dict[w]\n",
        "            tmp.append(merged_embeddings[idx])\n",
        "        m_embed_list.append(tmp)\n",
        "    return m_embed_list\n",
        "\n",
        "input_train = get_merged_embeddings(data_train)\n",
        "input_test = get_merged_embeddings(data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kagof006qING",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b893cd6f-6bce-452a-e2a5-992aa6851cec"
      },
      "source": [
        "print('final input size in embeddings format words X embeddings : {} X {}'.format(len(input_train[0]),len(input_train[0][0])))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final input size in embeddings format words X embeddings : 1385 X 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lVQnUSX1LZ6C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "506ca052-9d4e-4186-8f84-2780e16a27da"
      },
      "source": [
        "# Move the model to GPU\n",
        "sentiment_model = Sentiment_Model().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(sentiment_model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    \n",
        "    # Preparing input\n",
        "    input_batch, target_batch = prepare_batch_final(input_train,label_train_n, batch_size)\n",
        "    # Convert input into tensors and move them to GPU by uting tensor.to(device)\n",
        "    input_batch_torch = torch.from_numpy(np.array(input_batch)).float().to(device)\n",
        "    target_batch_torch = torch.from_numpy(np.array(target_batch)).view(-1).to(device)\n",
        "\n",
        "    # Set the flag to training\n",
        "    sentiment_model.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    outputs,_ = sentiment_model(input_batch_torch) \n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Set the flag to evaluation, which will 'turn off' the dropout\n",
        "    sentiment_model.eval()\n",
        "    outputs,_ = sentiment_model(input_batch_torch) \n",
        "    \n",
        "    # Evaluation loss and accuracy calculation\n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    if epoch % 5 == 4: \n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        acc = accuracy_score(predicted.cpu().numpy(),target_batch_torch.cpu().numpy())\n",
        "        f1 = f1_score(predicted.cpu().numpy(),target_batch_torch.cpu().numpy())\n",
        "        epoch_list.append(epoch+1)\n",
        "        f1_score_list.append(f1)\n",
        "        accuracy_score_list.append(acc)\n",
        "        print('Epoch: %d, loss: %.5f, train_acc: %.2f, f1: %.2f' %(epoch + 1, loss.item(), acc, f1))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5, loss: 0.70885, train_acc: 0.53, f1: 0.63\n",
            "Epoch: 10, loss: 0.66898, train_acc: 0.59, f1: 0.71\n",
            "Epoch: 15, loss: 0.67946, train_acc: 0.54, f1: 0.60\n",
            "Epoch: 20, loss: 0.67542, train_acc: 0.55, f1: 0.44\n",
            "Epoch: 25, loss: 0.65790, train_acc: 0.56, f1: 0.64\n",
            "Epoch: 30, loss: 0.66613, train_acc: 0.59, f1: 0.70\n",
            "Epoch: 35, loss: 0.66814, train_acc: 0.62, f1: 0.37\n",
            "Epoch: 40, loss: 0.68654, train_acc: 0.56, f1: 0.53\n",
            "Epoch: 45, loss: 0.67632, train_acc: 0.60, f1: 0.66\n",
            "Epoch: 50, loss: 0.64612, train_acc: 0.59, f1: 0.56\n",
            "Epoch: 55, loss: 0.62592, train_acc: 0.64, f1: 0.68\n",
            "Epoch: 60, loss: 0.64757, train_acc: 0.62, f1: 0.60\n",
            "Epoch: 65, loss: 0.61988, train_acc: 0.69, f1: 0.69\n",
            "Epoch: 70, loss: 0.65788, train_acc: 0.60, f1: 0.67\n",
            "Epoch: 75, loss: 0.62831, train_acc: 0.64, f1: 0.69\n",
            "Epoch: 80, loss: 0.57929, train_acc: 0.70, f1: 0.71\n",
            "Epoch: 85, loss: 0.60993, train_acc: 0.64, f1: 0.71\n",
            "Epoch: 90, loss: nan, train_acc: 0.54, f1: 0.00\n",
            "Epoch: 95, loss: nan, train_acc: 0.50, f1: 0.00\n",
            "Epoch: 100, loss: nan, train_acc: 0.49, f1: 0.00\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-2feNpG-LZx2"
      },
      "source": [
        "### 2.3.4. Save Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sflUAgV4L1o8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "27500107-953d-4cb3-8077-6c116bdb6a0d"
      },
      "source": [
        "torch.save(sentiment_model, save_path + 'ndes8735_sequence.pt')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Sentiment_Model. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4zFo6YppL6w3"
      },
      "source": [
        "### 2.3.5. Load Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OtNxLzDGMCan",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0b4cde99-98ee-4cac-bb71-4df958f61835"
      },
      "source": [
        "sentiment_model_saved = torch.load(save_path + 'ndes8735_sequence.pt')\n",
        "sentiment_model_saved.eval()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment_Model(\n",
              "  (lstm): LSTM(200, 50, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (linear): Linear(in_features=100, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a4mpRpocePLN"
      },
      "source": [
        "# 3 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KEW1zMgVMREr"
      },
      "source": [
        "## 3.1. Performance Evaluation\n",
        "\n",
        "\n",
        "You are required to provide the table with precision, recall, f1 of test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rn4LSqDkta9P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a46a8359-a9e3-4ead-c2f0-91b8a2ef4a8d"
      },
      "source": [
        "sentiment_model_saved = torch.load(save_path + 'ndes8735_sequence.pt')\n",
        "sentiment_model_saved.eval()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment_Model(\n",
              "  (lstm): LSTM(200, 50, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (linear): Linear(in_features=100, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qna23Unn1X-W"
      },
      "source": [
        "Only limited batch size can be tested. Anything more than 200 crashes the colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LPHCb-bneTI9",
        "colab": {}
      },
      "source": [
        "# Preparing input for 200 test samples\n",
        "batch_size = 200\n",
        "\n",
        "input_batch, target_batch = prepare_batch_final(input_test,label_test_n, batch_size)\n",
        "# Convert input into tensors and move them to GPU by uting tensor.to(device)\n",
        "input_batch_torch = torch.from_numpy(np.array(input_batch)).float().to(device)\n",
        "target_batch_torch = torch.from_numpy(np.array(target_batch)).view(-1).to(device)\n",
        "\n",
        "outputs,_ = sentiment_model_saved(input_batch_torch) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wtec8pVHvgic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8a7c377b-fe4c-41e4-e91e-5bcda30b9fa5"
      },
      "source": [
        "_, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(target_batch,predicted.cpu().numpy()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.63      0.68       107\n",
            "           1       0.64      0.76      0.70        93\n",
            "\n",
            "    accuracy                           0.69       200\n",
            "   macro avg       0.70      0.69      0.69       200\n",
            "weighted avg       0.70      0.69      0.69       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P28Z1k36MZuo"
      },
      "source": [
        "## 3.2. Hyperparameter Testing\n",
        "*You are required to draw a graph(y-axis: f1, x-axis: epoch) for test set and explain the optimal number of epochs based on the learning rate you have already chosen.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wTLyQEeZMZ2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0c661302-a460-437a-9303-1d89dca3d8bc"
      },
      "source": [
        "plt.plot(epoch_list, f1_score_list)\n",
        "plt.title('F1 Score vs epochs')\n",
        "plt.xlabel('number of epochs')\n",
        "plt.ylabel('F1 score')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sfv8rWTKPzeb"
      },
      "source": [
        "## Object Oriented Programming codes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TS23AjBRSZaX"
      },
      "source": [
        "*You can use multiple code snippets. Just add more if needed* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1hVmx4E52dXS",
        "colab": {}
      },
      "source": [
        "# If you used OOP style, use this section"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}